name: nv-mii

on:
  push:
    branches:
      - 'master'
      - 'staging**'
    paths-ignore:
      - 'docs/**'
  pull_request:
    paths:
      - '.github/workflows/nv-mii.yml'
      - 'requirements/**'
      - 'setup.py'
      - 'deepspeed/__init__.py'
      - 'deepspeed/inference/**'
      - '!deepspeed/inference/v2/**' # exclude v2 dir
  merge_group:
    branches: [ master ]
  schedule:
    - cron: "0 0 * * *"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  unit-tests:
    runs-on: [self-hosted, nvidia, cu116, v100]

    steps:
      - uses: actions/checkout@v2

      - name: environment
        run: |
          pip3 install -U --cache-dir $TORCH_CACHE torch --index-url https://download.pytorch.org/whl/cu118
          python -c "import torch; print('torch:', torch.__version__, torch)"
          python -c "import torch; print('CUDA available:', torch.cuda.is_available())"

      - name: Install MII
        run: |
          pip uninstall --yes deepspeed deepspeed-mii transformers
          pip install .[dev]
          pip install git+https://github.com/huggingface/transformers.git

      - name: Python environment
        run: |
          pip list

      - name: Unit tests
        run: |
          git clone https://github.com/microsoft/DeepSpeed-MII.git
          cd DeepSpeed-MII
          pip install .[dev]
          unset TORCH_CUDA_ARCH_LIST # only jit compile for current arch
          cd tests/legacy
          pytest $PYTEST_OPTS --forked -m "deepspeed" ./
