name: nv-flash-attn

on:
  workflow_dispatch:
  schedule:
    - cron: "0 0 * * *"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  unit-tests:
    runs-on: [self-hosted, nvidia, a6000]
    container:
      image: nvcr.io/nvidia/pytorch:24.09-py3
      ports:
        - 80
      options: --gpus all --shm-size "8G"

    steps:
      - uses: actions/checkout@v4

      - name: Check container state
        run: |
          ldd --version
          nvcc --version
          nvidia-smi
          python -c "import torch; print('torch:', torch.__version__, torch)"
          python -c "import torch; print('CUDA available:', torch.cuda.is_available())"
      - name: Install transformers
        run: |
          git clone --depth=1 https://github.com/huggingface/transformers
          cd transformers
          git rev-parse --short HEAD
          python -m pip install .
      - name: Install deepspeed
        run: |
          python -m pip install .[dev]
          ds_report
      - name: Install FlashAttention
        run: |
          python -m pip install flash-attn
      - name: Python environment
        run: |
          python -m pip list
      - name: Unit tests
        run: |
          unset TORCH_CUDA_ARCH_LIST # only jit compile for current arch
          cd tests
          DS_ALLOW_DEPRECATED_FP16=1 pytest $PYTEST_OPTS --forked -n 4 unit/ --torch_ver="1.10" --cuda_ver="11.1"

      - name: Open GitHub issue if nightly CI fails
        if: ${{ failure() && (github.event_name == 'schedule') }}
        uses: JasonEtco/create-an-issue@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          filename: .github/ISSUE_TEMPLATE/ci_failure_report.md
          update_existing: true
